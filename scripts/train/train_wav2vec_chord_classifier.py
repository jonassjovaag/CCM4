#!/usr/bin/env python3
"""
Train Wav2Vec â†’ Chord Classifier
=================================

Trains a neural network to map Wav2Vec features (768D) to chord labels.
Uses ground truth chord data generated by chord_ground_truth_trainer_wav2vec.py

Usage:
    # Step 1: Generate ground truth data (if not already done)
    python chord_ground_truth_trainer_wav2vec.py \
        --from-validation validation_results_20251007_170413.json \
        --gpu
    
    # Step 2: Train classifier
    python train_wav2vec_chord_classifier.py \
        --ground-truth-file ground_truth_data_wav2vec.json \
        --output-model models/wav2vec_chord_classifier.pt \
        --epochs 50 \
        --batch-size 32 \
        --gpu

Features:
- Loads Wav2Vec features from ground truth JSON
- Trains neural classifier (768D â†’ chord labels)
- Saves trained model for use in Chandra_trainer pipeline
- Reports accuracy and validation metrics
"""

import argparse
import json
import numpy as np
import os
from typing import List, Tuple, Dict
import torch

from hybrid_training.wav2vec_chord_classifier import Wav2VecChordClassifier, generate_harmonic_summary


def load_ground_truth_data(filepath: str) -> Tuple[np.ndarray, List[str], List[Dict]]:
    """
    Load ground truth data from JSON file
    
    Args:
        filepath: Path to ground truth JSON file
        
    Returns:
        Tuple of (features, labels, metadata)
            - features: [N, 768] array of Wav2Vec features
            - labels: List of N chord labels
            - metadata: List of N metadata dicts
    """
    print(f"ğŸ“‚ Loading ground truth data from: {filepath}")
    
    with open(filepath, 'r') as f:
        data = json.load(f)
    
    ground_truths = data.get('ground_truths', [])
    
    if not ground_truths:
        raise ValueError("No ground truth data found in file!")
    
    features = []
    labels = []
    metadata = []
    
    for gt in ground_truths:
        # Extract Wav2Vec features (handle both old and new format)
        wav2vec_features = None
        
        # New format (from generate_synthetic_chord_dataset.py)
        if 'wav2vec_features' in gt:
            wav2vec_features = gt['wav2vec_features']
        # Old format (from chord_ground_truth_trainer_wav2vec.py)
        elif 'audio_features' in gt:
            audio_features = gt.get('audio_features', {})
            wav2vec_features = audio_features.get('wav2vec_features')
        
        if wav2vec_features is None:
            print(f"âš ï¸  Skipping entry - no Wav2Vec features")
            continue
        
        # Extract chord label (handle both formats)
        chord_name = gt.get('chord_label', gt.get('chord_name', 'C'))
        
        features.append(wav2vec_features)
        labels.append(chord_name)
        metadata.append({
            'root': gt.get('root', 'C'),
            'chord_type': gt.get('chord_type', 'major'),
            'inversion': gt.get('inversion', 0),
            'octave': gt.get('octave', 4),
            'consonance': gt.get('consonance', 0.5)
        })
    
    features_array = np.array(features)
    
    print(f"âœ… Loaded {len(features_array)} samples")
    print(f"   Feature shape: {features_array.shape}")
    print(f"   Unique chords: {len(set(labels))}")
    print(f"   Chord distribution:")
    
    # Show top 10 most common chords
    from collections import Counter
    chord_counts = Counter(labels)
    for chord, count in chord_counts.most_common(10):
        print(f"      {chord}: {count}")
    
    return features_array, labels, metadata


def main():
    parser = argparse.ArgumentParser(description="Train Wav2Vec â†’ Chord Classifier")
    
    parser.add_argument('--ground-truth-file', type=str, 
                       default='ground_truth_data_wav2vec.json',
                       help='Ground truth JSON file with Wav2Vec features')
    parser.add_argument('--output-model', type=str,
                       default='models/wav2vec_chord_classifier.pt',
                       help='Output model file path')
    parser.add_argument('--epochs', type=int, default=50,
                       help='Number of training epochs')
    parser.add_argument('--batch-size', type=int, default=32,
                       help='Training batch size')
    parser.add_argument('--learning-rate', type=float, default=0.001,
                       help='Learning rate')
    parser.add_argument('--val-split', type=float, default=0.2,
                       help='Validation split ratio')
    parser.add_argument('--gpu', action='store_true',
                       help='Use GPU if available')
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("ğŸ“ Training Wav2Vec â†’ Chord Classifier")
    print("=" * 80)
    
    # Check if ground truth file exists
    if not os.path.exists(args.ground_truth_file):
        print(f"\nâŒ Ground truth file not found: {args.ground_truth_file}")
        print("\nğŸ’¡ Generate ground truth data first:")
        print("   python chord_ground_truth_trainer_wav2vec.py \\")
        print("       --from-validation validation_results_20251007_170413.json \\")
        print("       --gpu")
        return
    
    # Load data
    try:
        features, labels, metadata = load_ground_truth_data(args.ground_truth_file)
    except Exception as e:
        print(f"\nâŒ Error loading ground truth data: {e}")
        return
    
    # Check minimum data requirements
    if len(features) < 100:
        print(f"\nâš ï¸  Warning: Only {len(features)} samples available")
        print("   Minimum recommended: 1000 samples")
        print("   Training may not generalize well")
        
        response = input("\nContinue anyway? (y/n): ")
        if response.lower() != 'y':
            return
    
    # Initialize classifier
    print(f"\nğŸ”¬ Initializing classifier...")
    classifier = Wav2VecChordClassifier(input_dim=768, num_chord_types=len(set(labels)))
    
    # Determine device
    device = 'cpu'
    if args.gpu and torch.cuda.is_available():
        device = 'cuda'
        classifier = classifier.cuda()
        print("   Using GPU")
    elif args.gpu and torch.backends.mps.is_available():
        device = 'mps'
        classifier = classifier.to('mps')
        print("   Using MPS (Apple Silicon)")
    else:
        print("   Using CPU")
    
    # Train classifier
    print(f"\nğŸ“ Training...")
    history = classifier.train_classifier(
        features=features,
        labels=labels,
        epochs=args.epochs,
        batch_size=args.batch_size,
        learning_rate=args.learning_rate,
        val_split=args.val_split,
        verbose=True,
        device=device
    )
    
    # Save model
    print(f"\nğŸ’¾ Saving model...")
    os.makedirs(os.path.dirname(args.output_model), exist_ok=True)
    classifier.save(args.output_model)
    
    # Save training history
    history_file = args.output_model.replace('.pt', '_history.json')
    with open(history_file, 'w') as f:
        json.dump(history, f, indent=2)
    print(f"âœ… Training history saved to: {history_file}")
    
    # Test with a few predictions
    print(f"\nğŸ§ª Testing predictions...")
    test_samples = min(5, len(features))
    for i in range(test_samples):
        predicted = classifier.predict(features[i], device=device)
        actual = labels[i]
        match = "âœ…" if predicted == actual else "âŒ"
        print(f"   {match} Predicted: {predicted:10s} | Actual: {actual:10s}")
    
    # Generate harmonic summary
    all_predictions = classifier.predict_batch(features[:100], device=device)  # Sample 100
    summary = generate_harmonic_summary(all_predictions)
    print(f"\nğŸ“Š Harmonic Summary (sample):")
    for chord_type, percentage in summary.items():
        if percentage > 0:
            print(f"   {chord_type:12s}: {percentage:5.1f}%")
    
    print("\n" + "=" * 80)
    print("âœ… Training Complete!")
    print("=" * 80)
    print(f"\nModel saved to: {args.output_model}")
    print("\nNext steps:")
    print("1. Test the classifier on real audio")
    print("2. Integrate into Chandra_trainer.py pipeline")
    print("3. Retrain models (Georgia, Itzama, Nineteen) with new classifier")


if __name__ == "__main__":
    main()

