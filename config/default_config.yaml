# MusicHal 9000 - Default Configuration
# This file defines all configurable parameters for the system

# System metadata
system:
  name: "MusicHal 9000"
  version: "2.0"
  environment: "production"

# Audio Input Configuration
audio:
  input_device: null  # null = system default, or specify device index
  sample_rate: 44100
  buffer_size: 512
  channels: 1  # mono

# AudioOracle Configuration
audio_oracle:
  distance_threshold: 0.15
  distance_function: "euclidean"  # euclidean, cosine, manhattan
  feature_dimensions: 15
  adaptive_threshold: true
  max_pattern_length: 50
  chord_similarity_weight: 0.3
  use_mps: true  # Use Metal Performance Shaders (Mac) if available

  # Training-specific settings
  training:
    max_events: 15000
    hierarchical_enabled: true
    rhythmic_analysis_enabled: true
    correlation_analysis_enabled: true

# Memory Buffer Configuration
memory_buffer:
  max_duration_seconds: 180.0  # 3 minutes of history
  feature_dimensions: 4
  update_stats: true
  stats_window: 1000

# RhythmOracle Configuration
rhythm_oracle:
  enabled: true
  tempo_range: [40, 240]  # BPM
  beat_tracking: true
  syncopation_detection: true

# AI Agent Configuration
ai_agent:
  default_behavior: "imitate"  # imitate, contrast, lead
  autonomous_when_silent: true
  silence_threshold_seconds: 2.0

  # Behavior weights
  behavior_weights:
    imitate: 0.5
    contrast: 0.3
    lead: 0.2

  # Density controller
  density:
    min_notes_per_second: 0.1
    max_notes_per_second: 8.0
    default_density: 1.0

# Feature Mapper Configuration
feature_mapper:
  # MIDI output ranges
  velocity_range: [40, 120]
  pitch_range: [36, 96]  # C2 to C7

  # Voice separation
  melody_weight: 0.6
  bass_weight: 0.4

# MIDI Output Configuration
midi:
  port: "IAC Driver Melody Channel"  # Default MIDI port
  channel: 1
  velocity_curve: "linear"  # linear, exponential, logarithmic

# Performance Arc Configuration
performance_arc:
  enabled: true
  default_duration_minutes: 5
  phases:
    - name: "introduction"
      duration_percent: 0.2
      intensity: 0.3
    - name: "development"
      duration_percent: 0.5
      intensity: 0.7
    - name: "climax"
      duration_percent: 0.2
      intensity: 1.0
    - name: "resolution"
      duration_percent: 0.1
      intensity: 0.4

# Logging Configuration
logging:
  enabled: true
  log_dir: "logs"
  log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR

  # Performance logging
  performance_logging:
    enabled: true
    log_audio_analysis: true
    log_decisions: true
    log_midi_output: true

# Data Persistence Configuration
persistence:
  data_dir: "ai_learning_data"
  memory_file: "musical_memory.json"
  oracle_file: "polyphonic_audio_oracle_model.json"

  # Auto-save settings
  auto_save:
    enabled: true
    interval_seconds: 300  # 5 minutes

  # Backup settings
  backup:
    enabled: true
    max_backups: 10
    max_age_days: 30

# Data Safety Configuration (Phase 1 features)
data_safety:
  atomic_writes: true
  create_backups: true
  validate_on_save: true
  add_metadata: true
  max_retries: 3

  # Validation settings
  validation:
    strict_mode: false
    check_data_quality: true

# Feature Extraction Configuration
feature_extraction:
  # Neural audio features (MERT or Wav2Vec)
  wav2vec:
    enabled: true
    model: "m-a-p/MERT-v1-95M"  # MERT: music-specific model (768D, 24kHz)
    # Alternative: "facebook/wav2vec2-base" (768D, 16kHz)
    layer: 7  # Which transformer layer to use

  # Frequency analysis
  frequency_analysis:
    enabled: true
    min_frequency: 20.0
    max_frequency: 5000.0

  # Harmonic context
  harmonic_context:
    enabled: true
    chord_detection: true
    key_detection: true

  # Rhythmic context
  rhythmic_context:
    enabled: true
    beat_tracking: true
    tempo_estimation: true

# CLAP Style Detection Configuration (Phase 2.x)
style_detection:
  enabled: true  # Enable automatic style-aware mode selection
  model: "laion/clap-htsat-unfused"  # CLAP model for audio-text alignment
  # Alternative: "laion/larger_clap_music" (~1GB, more accurate)
  use_gpu: true
  auto_behavior_mode: true  # Auto-switch modes based on detected style
  confidence_threshold: 0.3  # Minimum confidence to switch modes

  # Style â†’ Behavior Mode Mappings
  style_mappings:
    ballad: shadow      # Intimate following
    jazz: shadow        # Supportive role
    blues: shadow       # Emotional support
    rock: couple        # Independent, loud
    funk: couple        # Rhythmic independence
    metal: couple       # Aggressive independence
    punk: couple        # Energetic independence
    ambient: mirror     # Balanced, contemplative
    classical: mirror   # Phrase-aware
    electronic: mirror  # Textural balance
    world: mirror       # Cultural sensitivity

  # Detection settings
  update_interval: 5.0  # Re-detect style every N seconds
  buffer_size: 3.0      # Audio buffer size for analysis (seconds)

# Hierarchical Analysis Configuration
hierarchical_analysis:
  enabled: true
  timescales: [0.1, 0.5, 2.0, 8.0]  # seconds
  perceptual_filtering: true
  significance_threshold: 0.5

# Training Configuration
training:
  # Chandra_trainer.py settings
  input_audio_dir: "input_audio"
  output_dir: "JSON"

  # Processing settings
  batch_size: 1
  verbose: true

  # Analysis components
  components:
    dual_perception: true
    hierarchical_analysis: true
    rhythmic_analysis: true
    music_theory_analysis: true
    correlation_analysis: true

# Visualization Configuration (if enabled)
visualization:
  enabled: false
  update_interval: 0.1  # seconds
  phrase_memory_viewport: true

# Performance Optimization
performance:
  # Thread pool settings
  max_workers: 4

  # Cache settings
  cache_size: 1000

  # GPU acceleration
  use_gpu: true
  gpu_device: 0

# Development/Debug Settings
debug:
  enabled: false
  verbose_logging: false
  profile_performance: false
  save_intermediate_results: false
